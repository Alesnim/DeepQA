{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alesnim/DeepQA/blob/master/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kF0KgYFBuShl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50f2c32e-1547-45d3-96ee-6377180afa45"
      },
      "cell_type": "code",
      "source": [
        "% ls "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D6wVGXuluVYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f37fd6a8-e4fc-4484-becd-98d9098b15c2"
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Alesnim/DeepQA.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepQA'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)   \u001b[K\rremote: Counting objects:  66% (2/3)   \u001b[K\rremote: Counting objects: 100% (3/3)   \u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 989 (delta 0), reused 0 (delta 0), pack-reused 986\u001b[K\n",
            "Receiving objects: 100% (989/989), 13.87 MiB | 12.31 MiB/s, done.\n",
            "Resolving deltas: 100% (579/579), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IVAiKNYmuiBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "996bc6e2-17e3-4770-934f-1b5bac9fbacc"
      },
      "cell_type": "code",
      "source": [
        "% ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mDeepQA\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QaA768jHu5J4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "import tensorflow as tf \n",
        "\n",
        "os.chdir('./DeepQA')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsdKNiVxu9Ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a160832a-f21d-4aaa-d459-1c1e504252b8"
      },
      "cell_type": "code",
      "source": [
        "! ls -a"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\t\t       data\t       .git\t   requirements.txt\n",
            "..\t\t       docker\t       .gitignore  ru_conv.txt\n",
            "chatbot\t\t       Dockerfile      LICENSE\t   save\n",
            "chatbot_miniature.png  Dockerfile.gpu  main.py\t   setup_server.sh\n",
            "chatbot_website        .dockerignore   README.md   testsuite.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zz1_DKnYvPQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5494
        },
        "outputId": "55833f37-034e-4f98-d861-14f23367cd8f"
      },
      "cell_type": "code",
      "source": [
        "! python main.py --corpus lightweight --datasetTag ru_conv --vocabularySize 10000"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to DeepQA v0.1 !\n",
            "\n",
            "TensorFlow detected: v1.12.0\n",
            "Training samples not found. Creating dataset...\n",
            "Constructing full dataset...\n",
            "Extract conversations: 100% 84921/84921 [01:01<00:00, 1378.70it/s]\n",
            "Loaded lightweight: 74672 words, 161341 QA\n",
            "Filtering words (vocabSize = 10000 and wordCount > 1)...\n",
            "Saving dataset...\n",
            "Loaded lightweight: 10004 words, 108939 QA\n",
            "Model creation...\n",
            "WARNING:tensorflow:From /content/DeepQA/chatbot/model.py:145: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
            "2018-11-11 12:48:27.188855: W tensorflow/python/util/util.cc:297] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2018-11-11 12:48:33.505904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-11 12:48:33.506360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-11-11 12:48:33.506411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-11 12:48:34.449246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-11 12:48:34.449308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-11 12:48:34.449336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-11 12:48:34.449621: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-11-11 12:48:34.449722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Initialize variables...\n",
            "WARNING: No previous model found, starting from clean directory: /content/DeepQA/save/model\n",
            "Start training (press Ctrl+C to save and exit)...\n",
            "\n",
            "----- Epoch 1/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 100 -- Loss 4.72 -- Perplexity 112.63\n",
            "----- Step 200 -- Loss 4.42 -- Perplexity 83.43\n",
            "----- Step 300 -- Loss 4.26 -- Perplexity 71.05\n",
            "----- Step 400 -- Loss 4.03 -- Perplexity 56.13\n",
            "Training: 100% 426/426 [03:49<00:00,  2.11it/s]\n",
            "Epoch finished in 0:03:49.092833\n",
            "\n",
            "----- Epoch 2/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 500 -- Loss 3.92 -- Perplexity 50.55\n",
            "----- Step 600 -- Loss 3.91 -- Perplexity 49.80\n",
            "----- Step 700 -- Loss 3.84 -- Perplexity 46.64\n",
            "----- Step 800 -- Loss 3.75 -- Perplexity 42.44\n",
            "Training: 100% 426/426 [03:44<00:00,  2.11it/s]\n",
            "Epoch finished in 0:03:44.931870\n",
            "\n",
            "----- Epoch 3/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 900 -- Loss 3.61 -- Perplexity 36.97\n",
            "----- Step 1000 -- Loss 3.61 -- Perplexity 36.95\n",
            "----- Step 1100 -- Loss 3.60 -- Perplexity 36.60\n",
            "----- Step 1200 -- Loss 3.64 -- Perplexity 37.96\n",
            "Training: 100% 426/426 [03:44<00:00,  2.11it/s]\n",
            "Epoch finished in 0:03:44.403044\n",
            "\n",
            "----- Epoch 4/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 1300 -- Loss 3.64 -- Perplexity 38.21\n",
            "----- Step 1400 -- Loss 3.52 -- Perplexity 33.90\n",
            "----- Step 1500 -- Loss 3.53 -- Perplexity 34.07\n",
            "----- Step 1600 -- Loss 3.53 -- Perplexity 34.24\n",
            "----- Step 1700 -- Loss 3.49 -- Perplexity 32.80\n",
            "Training: 100% 426/426 [03:44<00:00,  2.13it/s]\n",
            "Epoch finished in 0:03:44.751951\n",
            "\n",
            "----- Epoch 5/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 1800 -- Loss 3.32 -- Perplexity 27.68\n",
            "----- Step 1900 -- Loss 3.50 -- Perplexity 33.16\n",
            "----- Step 2000 -- Loss 3.34 -- Perplexity 28.34\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "----- Step 2100 -- Loss 3.36 -- Perplexity 28.85\n",
            "Training: 100% 426/426 [03:46<00:00,  2.09it/s]\n",
            "Epoch finished in 0:03:46.777744\n",
            "\n",
            "----- Epoch 6/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 2200 -- Loss 3.23 -- Perplexity 25.35\n",
            "----- Step 2300 -- Loss 3.23 -- Perplexity 25.19\n",
            "----- Step 2400 -- Loss 3.29 -- Perplexity 26.74\n",
            "----- Step 2500 -- Loss 3.32 -- Perplexity 27.65\n",
            "Training: 100% 426/426 [03:45<00:00,  2.11it/s]\n",
            "Epoch finished in 0:03:45.025354\n",
            "\n",
            "----- Epoch 7/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 2600 -- Loss 3.07 -- Perplexity 21.46\n",
            "----- Step 2700 -- Loss 3.23 -- Perplexity 25.18\n",
            "----- Step 2800 -- Loss 3.27 -- Perplexity 26.19\n",
            "----- Step 2900 -- Loss 3.29 -- Perplexity 26.82\n",
            "Training: 100% 426/426 [03:45<00:00,  2.09it/s]\n",
            "Epoch finished in 0:03:45.551343\n",
            "\n",
            "----- Epoch 8/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 3000 -- Loss 3.01 -- Perplexity 20.31\n",
            "----- Step 3100 -- Loss 3.17 -- Perplexity 23.69\n",
            "----- Step 3200 -- Loss 3.12 -- Perplexity 22.66\n",
            "----- Step 3300 -- Loss 3.13 -- Perplexity 22.98\n",
            "----- Step 3400 -- Loss 3.08 -- Perplexity 21.80\n",
            "Training: 100% 426/426 [03:44<00:00,  2.10it/s]\n",
            "Epoch finished in 0:03:44.831413\n",
            "\n",
            "----- Epoch 9/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 3500 -- Loss 3.10 -- Perplexity 22.17\n",
            "----- Step 3600 -- Loss 2.81 -- Perplexity 16.66\n",
            "----- Step 3700 -- Loss 3.03 -- Perplexity 20.74\n",
            "----- Step 3800 -- Loss 3.01 -- Perplexity 20.27\n",
            "Training: 100% 426/426 [03:44<00:00,  2.09it/s]\n",
            "Epoch finished in 0:03:44.798393\n",
            "\n",
            "----- Epoch 10/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 3900 -- Loss 2.84 -- Perplexity 17.06\n",
            "----- Step 4000 -- Loss 2.97 -- Perplexity 19.49\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "----- Step 4100 -- Loss 3.05 -- Perplexity 21.20\n",
            "----- Step 4200 -- Loss 2.93 -- Perplexity 18.71\n",
            "Training: 100% 426/426 [03:46<00:00,  2.08it/s]\n",
            "Epoch finished in 0:03:46.741071\n",
            "\n",
            "----- Epoch 11/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 4300 -- Loss 2.84 -- Perplexity 17.10\n",
            "----- Step 4400 -- Loss 2.80 -- Perplexity 16.44\n",
            "----- Step 4500 -- Loss 2.90 -- Perplexity 18.12\n",
            "----- Step 4600 -- Loss 2.86 -- Perplexity 17.53\n",
            "Training: 100% 426/426 [03:46<00:00,  2.08it/s]\n",
            "Epoch finished in 0:03:46.266211\n",
            "\n",
            "----- Epoch 12/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 4700 -- Loss 2.85 -- Perplexity 17.33\n",
            "----- Step 4800 -- Loss 2.81 -- Perplexity 16.57\n",
            "----- Step 4900 -- Loss 2.93 -- Perplexity 18.70\n",
            "----- Step 5000 -- Loss 2.87 -- Perplexity 17.62\n",
            "----- Step 5100 -- Loss 2.87 -- Perplexity 17.55\n",
            "Training: 100% 426/426 [03:46<00:00,  2.09it/s]\n",
            "Epoch finished in 0:03:46.060856\n",
            "\n",
            "----- Epoch 13/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 5200 -- Loss 2.76 -- Perplexity 15.73\n",
            "----- Step 5300 -- Loss 2.73 -- Perplexity 15.40\n",
            "----- Step 5400 -- Loss 2.65 -- Perplexity 14.12\n",
            "----- Step 5500 -- Loss 2.77 -- Perplexity 16.04\n",
            "Training: 100% 426/426 [03:46<00:00,  2.11it/s]\n",
            "Epoch finished in 0:03:46.637832\n",
            "\n",
            "----- Epoch 14/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 5600 -- Loss 2.57 -- Perplexity 13.07\n",
            "----- Step 5700 -- Loss 2.64 -- Perplexity 14.04\n",
            "----- Step 5800 -- Loss 2.66 -- Perplexity 14.34\n",
            "----- Step 5900 -- Loss 2.51 -- Perplexity 12.34\n",
            "Training: 100% 426/426 [03:47<00:00,  2.09it/s]\n",
            "Epoch finished in 0:03:47.107119\n",
            "\n",
            "----- Epoch 15/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 6000 -- Loss 2.61 -- Perplexity 13.65\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "----- Step 6100 -- Loss 2.59 -- Perplexity 13.33\n",
            "----- Step 6200 -- Loss 2.62 -- Perplexity 13.74\n",
            "----- Step 6300 -- Loss 2.67 -- Perplexity 14.51\n",
            "Training: 100% 426/426 [03:47<00:00,  2.07it/s]\n",
            "Epoch finished in 0:03:47.460367\n",
            "\n",
            "----- Epoch 16/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 6400 -- Loss 2.58 -- Perplexity 13.21\n",
            "----- Step 6500 -- Loss 2.40 -- Perplexity 11.07\n",
            "----- Step 6600 -- Loss 2.60 -- Perplexity 13.42\n",
            "----- Step 6700 -- Loss 2.47 -- Perplexity 11.83\n",
            "----- Step 6800 -- Loss 2.69 -- Perplexity 14.73\n",
            "Training: 100% 426/426 [03:46<00:00,  2.10it/s]\n",
            "Epoch finished in 0:03:46.062736\n",
            "\n",
            "----- Epoch 17/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 6900 -- Loss 2.47 -- Perplexity 11.82\n",
            "----- Step 7000 -- Loss 2.52 -- Perplexity 12.38\n",
            "----- Step 7100 -- Loss 2.47 -- Perplexity 11.83\n",
            "----- Step 7200 -- Loss 2.52 -- Perplexity 12.39\n",
            "Training: 100% 426/426 [03:46<00:00,  2.12it/s]\n",
            "Epoch finished in 0:03:46.547683\n",
            "\n",
            "----- Epoch 18/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 7300 -- Loss 2.26 -- Perplexity 9.63\n",
            "----- Step 7400 -- Loss 2.44 -- Perplexity 11.47\n",
            "----- Step 7500 -- Loss 2.31 -- Perplexity 10.09\n",
            "----- Step 7600 -- Loss 2.36 -- Perplexity 10.58\n",
            "Training: 100% 426/426 [03:46<00:00,  2.09it/s]\n",
            "Epoch finished in 0:03:46.702204\n",
            "\n",
            "----- Epoch 19/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 7700 -- Loss 2.26 -- Perplexity 9.59\n",
            "----- Step 7800 -- Loss 2.27 -- Perplexity 9.66\n",
            "----- Step 7900 -- Loss 2.36 -- Perplexity 10.62\n",
            "----- Step 8000 -- Loss 2.38 -- Perplexity 10.77\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "Training: 100% 426/426 [03:46<00:00,  2.08it/s]\n",
            "Epoch finished in 0:03:46.797551\n",
            "\n",
            "----- Epoch 20/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 8100 -- Loss 2.22 -- Perplexity 9.20\n",
            "----- Step 8200 -- Loss 2.31 -- Perplexity 10.04\n",
            "----- Step 8300 -- Loss 2.43 -- Perplexity 11.31\n",
            "----- Step 8400 -- Loss 2.35 -- Perplexity 10.54\n",
            "----- Step 8500 -- Loss 2.27 -- Perplexity 9.72\n",
            "Training: 100% 426/426 [03:46<00:00,  2.09it/s]\n",
            "Epoch finished in 0:03:46.135701\n",
            "\n",
            "----- Epoch 21/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 8600 -- Loss 2.17 -- Perplexity 8.72\n",
            "----- Step 8700 -- Loss 2.34 -- Perplexity 10.42\n",
            "----- Step 8800 -- Loss 2.18 -- Perplexity 8.89\n",
            "----- Step 8900 -- Loss 2.30 -- Perplexity 10.00\n",
            "Training: 100% 426/426 [03:46<00:00,  2.05it/s]\n",
            "Epoch finished in 0:03:46.428776\n",
            "\n",
            "----- Epoch 22/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 9000 -- Loss 2.15 -- Perplexity 8.56\n",
            "----- Step 9100 -- Loss 2.14 -- Perplexity 8.48\n",
            "----- Step 9200 -- Loss 2.20 -- Perplexity 9.05\n",
            "----- Step 9300 -- Loss 2.21 -- Perplexity 9.15\n",
            "Training: 100% 426/426 [03:45<00:00,  2.09it/s]\n",
            "Epoch finished in 0:03:45.828736\n",
            "\n",
            "----- Epoch 23/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 9400 -- Loss 1.94 -- Perplexity 6.99\n",
            "----- Step 9500 -- Loss 2.12 -- Perplexity 8.34\n",
            "----- Step 9600 -- Loss 2.10 -- Perplexity 8.15\n",
            "----- Step 9700 -- Loss 2.04 -- Perplexity 7.70\n",
            "Training: 100% 426/426 [03:46<00:00,  2.10it/s]\n",
            "Epoch finished in 0:03:46.201715\n",
            "\n",
            "----- Epoch 24/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 9800 -- Loss 1.94 -- Perplexity 6.94\n",
            "----- Step 9900 -- Loss 1.99 -- Perplexity 7.34\n",
            "----- Step 10000 -- Loss 1.98 -- Perplexity 7.24\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "----- Step 10100 -- Loss 2.15 -- Perplexity 8.55\n",
            "----- Step 10200 -- Loss 2.08 -- Perplexity 8.02\n",
            "Training: 100% 426/426 [03:47<00:00,  2.11it/s]\n",
            "Epoch finished in 0:03:47.674696\n",
            "\n",
            "----- Epoch 25/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 10300 -- Loss 1.91 -- Perplexity 6.73\n",
            "----- Step 10400 -- Loss 1.98 -- Perplexity 7.24\n",
            "----- Step 10500 -- Loss 2.06 -- Perplexity 7.81\n",
            "----- Step 10600 -- Loss 1.98 -- Perplexity 7.24\n",
            "Training: 100% 426/426 [03:47<00:00,  2.06it/s]\n",
            "Epoch finished in 0:03:47.389225\n",
            "\n",
            "----- Epoch 26/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 10700 -- Loss 1.91 -- Perplexity 6.73\n",
            "----- Step 10800 -- Loss 1.90 -- Perplexity 6.69\n",
            "----- Step 10900 -- Loss 1.94 -- Perplexity 6.97\n",
            "----- Step 11000 -- Loss 1.95 -- Perplexity 7.03\n",
            "Training: 100% 426/426 [03:47<00:00,  2.10it/s]\n",
            "Epoch finished in 0:03:47.309736\n",
            "\n",
            "----- Epoch 27/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 11100 -- Loss 1.84 -- Perplexity 6.28\n",
            "----- Step 11200 -- Loss 1.85 -- Perplexity 6.35\n",
            "----- Step 11300 -- Loss 1.90 -- Perplexity 6.68\n",
            "----- Step 11400 -- Loss 1.97 -- Perplexity 7.19\n",
            "----- Step 11500 -- Loss 1.93 -- Perplexity 6.92\n",
            "Training: 100% 426/426 [03:47<00:00,  2.07it/s]\n",
            "Epoch finished in 0:03:47.352062\n",
            "\n",
            "----- Epoch 28/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 11600 -- Loss 1.85 -- Perplexity 6.33\n",
            "----- Step 11700 -- Loss 1.86 -- Perplexity 6.42\n",
            "----- Step 11800 -- Loss 1.93 -- Perplexity 6.88\n",
            "----- Step 11900 -- Loss 1.96 -- Perplexity 7.07\n",
            "Training: 100% 426/426 [03:45<00:00,  2.11it/s]\n",
            "Epoch finished in 0:03:45.772276\n",
            "\n",
            "----- Epoch 29/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 12000 -- Loss 1.72 -- Perplexity 5.59\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "----- Step 12100 -- Loss 1.73 -- Perplexity 5.66\n",
            "----- Step 12200 -- Loss 1.83 -- Perplexity 6.24\n",
            "----- Step 12300 -- Loss 1.84 -- Perplexity 6.30\n",
            "Training: 100% 426/426 [03:46<00:00,  2.13it/s]\n",
            "Epoch finished in 0:03:46.045298\n",
            "\n",
            "----- Epoch 30/30 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 12400 -- Loss 1.70 -- Perplexity 5.49\n",
            "----- Step 12500 -- Loss 1.68 -- Perplexity 5.34\n",
            "----- Step 12600 -- Loss 1.90 -- Perplexity 6.70\n",
            "----- Step 12700 -- Loss 1.82 -- Perplexity 6.14\n",
            "Training: 100% 426/426 [03:46<00:00,  2.09it/s]\n",
            "Epoch finished in 0:03:46.763972\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "The End! Thanks for using this program\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TXW1yOUTz0R2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! git config --global user.email alesnim@gmail.com\n",
        "! git config --global user.name \"Alesnim\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I3iV19ePvXPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8742059a-866e-4591-90e1-b47d1aa55ee5"
      },
      "cell_type": "code",
      "source": [
        "! git commit -m \"Add save model\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 411619f] Add save model\n",
            " 7 files changed, 30 insertions(+)\n",
            " create mode 100644 save/model/checkpoint\n",
            " create mode 100644 save/model/events.out.tfevents.1541940516.72dcc30370af\n",
            " create mode 100644 save/model/model.ckpt\n",
            " create mode 100644 save/model/model.ckpt.data-00000-of-00001\n",
            " create mode 100644 save/model/model.ckpt.index\n",
            " create mode 100644 save/model/model.ckpt.meta\n",
            " create mode 100644 save/model/params.ini\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uRMFdwZSRK2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5381688e-7dc5-4995-a740-dd524ab36827"
      },
      "cell_type": "code",
      "source": [
        "! git push origin master"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "btUZvtUjScVh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}